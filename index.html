<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CAR: Chronologically Accurate Retrieval for Temporal Grounding of Motion-Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/javascript">
    /* play video twice as fast */
    document.getElementById("replay-video").defaultPlaybackRate = 2.0;
  </script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Chronologically Accurate Retrieval for Temporal Grounding of <br/>  Motion-Language Models</h1>
          <h2 class="title is-size-4 publication-title">to appear at ECCV 2024</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.kfworks.com">Kent Fujiwara</a></span>
            <span class="author-block">
              <a href="https://mikittt.github.io">Mikihiro Tanaka</a>,</span>
            <span class="author-block">
              <a href="https://yu1ut.com">Qing Yu</a>,</span>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">LY Corporation</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content has-text-centered">
        <video id="replay-video"
               autoplay
               controls
               muted
               preload
               loop
               playsinline
               width="100%">
          <source src="./static/videos/examples.mp4"
                  type="video/mp4">
        </video>
      </div>
      <h2 class="subtitle has-text-centered">
       Chronologically Accurate Retrieval (CAR).
       We present a simple strategy to reinforce motion-language models and achieve better temporal alignment between text and motion.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            With the release of large-scale motion datasets with textual annotations, the task of establishing a robust latent space for language and 3D human motion has recently witnessed a surge of interest. 
            Despite these efforts to align language and motion representations, we claim that the temporal element is often overlooked, especially for compound actions, resulting in chronological inaccuracies. 
            To shed light on the temporal alignment in motion-language latent spaces, we propose Chronologically Accurate Retrieval (CAR) to evaluate the chronological understanding of the models. 
            We decompose textual descriptions into events, and prepare negative text samples by shuffling the order of events in compound action descriptions. 
            We then design a simple task for motion-language models to retrieve the more likely text from the ground truth and its chronologically shuffled version. 
            CAR reveals many cases where current motion-language models fail to distinguish the event chronology of human motion, despite their impressive performance in terms of conventional evaluation metrics. 
            To achieve better temporal alignment between text and motion, we further propose to use these texts with shuffled sequence of events as negative samples during training to reinforce the motion-language models. 
            We conduct experiments on text-motion retrieval and text-to-motion generation using the reinforced motion-language models, which demonstrate improved performance over conventional approaches, indicating the necessity to consider temporal elements in motion-language alignment.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Proposal</h2>
    <h3 class="title is-4">CAR: Chronologically Accurate Retrieval</h3>
    <div class="content">
      <p>
        To analyze the text-motion alignment, we use the text annotations provided in <a href="https://github.com/EricGuo5513/HumanML3D" class="external-link" target="_blank">HumanML3D</a>.
        We decompose the text descriptions into events using off the shelf LLM.
        We leverage the event descriptions to conduct a test for the chronological understanding of the motion-language models.
        We shuffle the order of events in the text descriptions to create negative samples for the models to distinguish.
        CAR measures the success rate of models in retrieving the description with the correct order.
      </p>
      <center><img src="./static/images/car.jpg"/></center>
    </div>
    <h3 class="title is-4">Framework</h3>
    <div class="content">
      <p>
        We propose a simple solution to reinforce motion-language models in terms of chronology.
        In addition to the original text descriptions, we also use the shuffled texts as negative samples during contrastive learning
        Negative shuffled samples are important resource for models to comprehend the correct order of events.
      </p>
      <center><img src="./static/images/overview.jpg"/></center>
    </div>

    
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Experiments</h2>

        <h3 class="title is-4">Text-Motion Retrieval</h3>
        <div class="content has-text-justified">
          <p>
            Comparison of retrieval between <a href="https://arxiv.org/abs/2305.00976" class="external-link" target="_blank">TMR</a> and the proposed method. 
            Given a motion, models are asked to retrieve the correct description from original and shuffled texts.
            The reinforced model from our proposal shows better performance in distinguishing the correct order of events.
          </p>
          <div class="content has-text-centered">
            <img src="./static/images/retrieval.jpg"/>
          </div>
        </div>

        <h3 class="title is-4">Motion Generation</h3>
        <div class="content has-text-justified">
          <p>
            Comparison of generated motions between <a href="https://arxiv.org/abs/2305.00976" class="external-link" target="_blank">T2M-GPT</a> and the same model reinfoced by our text encoder. 
            The resulting motions from our method capture all the events that are indicated in the description in the correct order.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/generation.jpg"/>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{Fujiwara_2024_ECCV, 
      author = {Kent Fujiwara and Mikihiro Tanaka and Qing Yu}, 
      title = {Chronologically Accurate Retrieval for Temporal Grounding of Motion-Language Models}, 
      booktitle = {Proc. of the European Conf. on Computer Vision (ECCV)}, 
      year = {2024}, 
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            We express our gratitude to the authors of <a href="https://github.com/nerfies/nerfies.github.io" class="external-link">Nerfies</a> for generously open sourcing the template of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
